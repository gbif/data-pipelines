# Set everything to be logged to the console
log4j.rootCategory=INFO, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.out
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} [%X{step}] [%X{datasetId}] %p %c{1}: %m%n
# Settings to quiet third party logs that are too verbose
log4j.logger.au.org.ala=INFO
log4j.logger.org.spark-project.jetty=WARN
log4j.logger.org.gbif.common.parsers=ERROR
log4j.logger.org.gbif.geocode.api.cache=ERROR
log4j.logger.org.gbif.geocode.api.cache.GeocodeBitmapCache=ERROR
log4j.logger.org.gbif.pipelines.core.parsers.location.cache.GeocodeBitmapCache=ERROR
log4j.logger.org.spark_project.jetty.servlet.ServletContextHandler=ERROR
log4j.logger.org.eclipse.jetty.server.handler.ContextHandler=ERROR
log4j.logger.org.gbif.dwc.terms.TermFactory=ERROR
log4j.logger.org.apache.beam.runners.spark.translation=ERROR
log4j.logger.ServletContextHandler=ERROR
project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark=ERROR
log4j.logger.org.eclipse.jetty=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=ERROR
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=ERROR
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
log4j.logger.org.apache.beam=ERROR
# SPARK-9183: Settings to avoid annoying messages when looking up
# nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
